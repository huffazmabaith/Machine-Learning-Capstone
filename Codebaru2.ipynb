{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a42f2e2-7ece-4393-9c27-5a6de3802e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler,LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1aa3c710-c244-4556-b751-1d9e8a1cf03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Data_v.4.xlsx')\n",
    "data=data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c89d4e2f-9603-435e-94c4-3e3b8417f877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "features = ['Category', 'City', 'Rating', 'Price']\n",
    "X = data[features].copy()\n",
    "\n",
    "# Encode categorical features\n",
    "le_category = LabelEncoder()\n",
    "le_city = LabelEncoder()\n",
    "X['Category'] = le_category.fit_transform(X['Category'])\n",
    "X['City'] = le_city.fit_transform(X['City'])\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = MinMaxScaler()\n",
    "X[['Rating', 'Price']] = scaler.fit_transform(X[['Rating', 'Price']])\n",
    "\n",
    "# Convert to numpy array\n",
    "X = X.values\n",
    "\n",
    "# Step 2: Feature Encoding\n",
    "# One-hot encode Category and City\n",
    "num_categories = len(le_category.classes_)\n",
    "num_cities = len(le_city.classes_)\n",
    "X_encoded = np.zeros((X.shape[0], num_categories + num_cities + 2))\n",
    "X_encoded[:, :num_categories] = tf.keras.utils.to_categorical(X[:, 0], num_classes=num_categories)\n",
    "X_encoded[:, num_categories:num_categories+num_cities] = tf.keras.utils.to_categorical(X[:, 1], num_classes=num_cities)\n",
    "X_encoded[:, -2:] = X[:, 2:]  # Rating and Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75166609-d695-4ea1-a36a-2d9af6a4be73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "16/16 [==============================] - 1s 29ms/step - loss: 0.2232 - val_loss: 0.1989\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1716 - val_loss: 0.1351\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.1039 - val_loss: 0.0743\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0623 - val_loss: 0.0546\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0511 - val_loss: 0.0476\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0453 - val_loss: 0.0416\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0397 - val_loss: 0.0362\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.0342 - val_loss: 0.0306\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 0s 16ms/step - loss: 0.0293 - val_loss: 0.0260\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.0254 - val_loss: 0.0226\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0222 - val_loss: 0.0196\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 0s 17ms/step - loss: 0.0197 - val_loss: 0.0173\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.0176 - val_loss: 0.0156\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0159 - val_loss: 0.0142\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0144 - val_loss: 0.0128\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0130 - val_loss: 0.0117\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0108\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 0.0099\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0094 - val_loss: 0.0089\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0084 - val_loss: 0.0082\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0067 - val_loss: 0.0069\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0059 - val_loss: 0.0064\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0054 - val_loss: 0.0060\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0042 - val_loss: 0.0051\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a7a29ae0a0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Model Architecture\n",
    "input_dim = X_encoded.shape[1]\n",
    "hidden_dim = 64\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(hidden_dim, activation='relu', input_shape=(input_dim,)),\n",
    "    tf.keras.layers.Dense(hidden_dim, activation='relu'),\n",
    "    tf.keras.layers.Dense(input_dim, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Step 4: Training\n",
    "X_train, X_val = train_test_split(X_encoded, test_size=0.2, random_state=42)\n",
    "model.fit(X_train, X_train, epochs=50, batch_size=32, validation_data=(X_val, X_val), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad8f92ff-c7a8-4c8f-bf55-f052cbab42f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Create a Custom Model Class\n",
    "class RecommendationModel(tf.keras.Model):\n",
    "    def __init__(self, model, data, le_category, le_city, scaler, num_categories, num_cities):\n",
    "        super(RecommendationModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.data = data\n",
    "        self.le_category = le_category\n",
    "        self.le_city = le_city\n",
    "        self.scaler = scaler\n",
    "        self.num_categories = num_categories\n",
    "        self.num_cities = num_cities\n",
    "        self.input_dim = num_categories + num_cities + 2\n",
    "        self.all_embeddings = None\n",
    "    \n",
    "    def compute_all_embeddings(self):\n",
    "        X = self.data[['Category', 'City', 'Rating', 'Price']].copy()\n",
    "        X['Category'] = self.le_category.transform(X['Category'])\n",
    "        X['City'] = self.le_city.transform(X['City'])\n",
    "        X[['Rating', 'Price']] = self.scaler.transform(X[['Rating', 'Price']])\n",
    "        X_encoded = np.zeros((X.shape[0], self.input_dim))\n",
    "        X_encoded[:, :self.num_categories] = tf.keras.utils.to_categorical(X['Category'], num_classes=self.num_categories)\n",
    "        X_encoded[:, self.num_categories:self.num_categories+self.num_cities] = tf.keras.utils.to_categorical(X['City'], num_classes=self.num_cities)\n",
    "        X_encoded[:, -2:] = X[['Rating', 'Price']]\n",
    "        self.all_embeddings = self.model.predict(X_encoded)\n",
    "    \n",
    "    def get_feature_vector(self, attraction_name):\n",
    "        attraction = self.data[self.data['Place_Name'] == attraction_name].iloc[0]\n",
    "        features = [\n",
    "            self.le_category.transform([attraction['Category']])[0],\n",
    "            self.le_city.transform([attraction['City']])[0],\n",
    "            attraction['Rating'],\n",
    "            attraction['Price']\n",
    "        ]\n",
    "        encoded = np.zeros((1, self.input_dim))\n",
    "        encoded[0, :self.num_categories] = tf.keras.utils.to_categorical(features[0], num_classes=self.num_categories)\n",
    "        encoded[0, self.num_categories:self.num_categories+self.num_cities] = tf.keras.utils.to_categorical(features[1], num_classes=self.num_cities)\n",
    "        encoded[0, -2:] = self.scaler.transform([features[2:]])\n",
    "        return encoded\n",
    "    \n",
    "    def get_recommendations(self, attraction_name, top_k=10):\n",
    "        if self.all_embeddings is None:\n",
    "            self.compute_all_embeddings()\n",
    "        \n",
    "        query_vector = self.get_feature_vector(attraction_name)\n",
    "        query_embedding = self.model.predict(query_vector)\n",
    "        \n",
    "        similarities = np.dot(self.all_embeddings, query_embedding.T).flatten()\n",
    "        top_indices = similarities.argsort()[::-1][1:top_k+1]  # Exclude the query itself\n",
    "        top_attractions = self.data.iloc[top_indices]['Place_Name'].tolist()\n",
    "        top_similarities = similarities[top_indices].tolist()\n",
    "        \n",
    "        return list(zip(top_attractions, top_similarities))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b944446-76d8-48e5-9486-ff9e9687d524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Create an Instance of the Custom Model\n",
    "recommendation_model = RecommendationModel(\n",
    "    model=model,\n",
    "    data=data,\n",
    "    le_category=le_category,\n",
    "    le_city=le_city,\n",
    "    scaler=scaler,\n",
    "    num_categories=num_categories,\n",
    "    num_cities=num_cities\n",
    ")\n",
    "\n",
    "# Step 7: Save the Model\n",
    "# Save the TensorFlow model\n",
    "model.save('recommendation_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f8d5060-8988-456f-bdc3-cbc7f195e97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save other components\n",
    "with open('recommendation_model_components.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'data': data,\n",
    "        'le_category': le_category,\n",
    "        'le_city': le_city,\n",
    "        'scaler': scaler,\n",
    "        'num_categories': num_categories,\n",
    "        'num_cities': num_cities\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "146f7a0a-3e0b-436f-820f-1a3c8aac3987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Load the Model (this would typically be in a different script)\n",
    "# Load the TensorFlow model\n",
    "loaded_model = tf.keras.models.load_model('recommendation_model_weights.h5')\n",
    "\n",
    "# Load other components\n",
    "with open('recommendation_model_components.pkl', 'rb') as f:\n",
    "    components = pickle.load(f)\n",
    "\n",
    "# Recreate the RecommendationModel\n",
    "loaded_recommendation_model = RecommendationModel(\n",
    "    model=loaded_model,\n",
    "    data=components['data'],\n",
    "    le_category=components['le_category'],\n",
    "    le_city=components['le_city'],\n",
    "    scaler=components['scaler'],\n",
    "    num_categories=components['num_categories'],\n",
    "    num_cities=components['num_cities']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa124ff1-29f7-4341-96ed-741975279a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 5ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Top 10 recommendations similar to Monumen Nasional:\n",
      "Museum Bank Indonesia: 2.459745407104492\n",
      "Museum Sasmita Loka Ahmad Yani: 2.459745407104492\n",
      "Museum Kebangkitan Nasional: 2.459745407104492\n",
      "Perpustakaan Nasional: 2.459695339202881\n",
      "Monumen Nasional: 2.4406087398529053\n",
      "Taman Ismail Marzuki: 2.440218448638916\n",
      "Museum Nasional: 2.440218448638916\n",
      "Museum Tengah Kebun: 2.4400830268859863\n",
      "Istana Negara Republik Indonesia: 2.4400830268859863\n",
      "Kota Tua: 2.4400830268859863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\capstone\\lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Use the Loaded Model for Recommendations\n",
    "query_attraction = \"Monumen Nasional\"  # Replace with an actual attraction from your dataset\n",
    "recommendations = loaded_recommendation_model.get_recommendations(query_attraction, top_k=10)\n",
    "print(f\"Top 10 recommendations similar to {query_attraction}:\")\n",
    "for attraction, similarity in recommendations:\n",
    "    print(f\"{attraction}: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "628538fb-b41e-4603-8d7f-559cb1b58da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Museum Bank Indonesia', 2.459745407104492),\n",
       " ('Museum Sasmita Loka Ahmad Yani', 2.459745407104492),\n",
       " ('Museum Kebangkitan Nasional', 2.459745407104492),\n",
       " ('Perpustakaan Nasional', 2.459695339202881),\n",
       " ('Monumen Nasional', 2.4406087398529053),\n",
       " ('Taman Ismail Marzuki', 2.440218448638916),\n",
       " ('Museum Nasional', 2.440218448638916),\n",
       " ('Museum Tengah Kebun', 2.4400830268859863),\n",
       " ('Istana Negara Republik Indonesia', 2.4400830268859863),\n",
       " ('Kota Tua', 2.4400830268859863)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5d439e-c02a-402c-9c08-43b6932ef532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
